+--------------------------+
                                  |                CS 140                |
                     | PROJECT 2: USER PROGRAMS        |
                     |            DESIGN DOCUMENT             |
                     +--------------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

Tongda Zhang <tdzhang@stanford.edu>
Bing Han <bhan11@stanford.edu>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

                           ARGUMENT PASSING
                           ================

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

Answer:
-- changes in process.h--
  ->add a macro define
  #define MAX_FILE_NAME 14       /*the max length of file name*/


  ->add a structure
  /*load info struct used for process_execute*/
  struct load_info_block{
        char * full_line;                             /*full command line string*/
        struct semaphore sema_loaded; /*semaphore used to load thread*/
        bool success;             /*whether the thread is loaded successfully*/
  };



---- ALGORITHMS ----

>> A2: Briefly describe how you implemented argument parsing.  How do
>> you arrange for the elements of argv[] to be in the right order?
>> How do you avoid overflowing the stack page?


Answer:
We pass the full line (including the command and its argument) to process_execute, then wrap it in a struct “load_info_block” together with other load-helping variables (sema, success_flag, and so on) and pass the struct as the argument of start_process. Then in load(), after successfully setup_stack, we call push_args2stack() to push those command arguments into stack. We first count the number of arguments to get “argc”. Then push to args in reverse order, meaning that the last argument gets pushed first and occupies the higher address space and then one-by-one. During these pushes, we also keep track of *esp after each push action since we will push the address of arguments in the following pushes. Then we push 0 bytes for padding to ensure *esp is always multiple of 4, and we push a 4-byte maker 0 as well. Then we push the address of arguments we stored previously in the reverse order. At last we push the current *esp (the address of argv[0]), argc, and 4-byte 0 (as the return address) into the stack one-by-one.


In each push action, we first decrease the *esp by the size of the argument to be pushed, and check the decreased esp is still pointing to valid address space (between initial_esp and initial_esp-PGSIZE) without overflowing the stack page. If check passed, we do a memory copy to copy the value of the argument to the location where esp points to.


To avoid overflowing the stack page, we define a esp_limit, which is initial esp minus PGSIZE. Then every time we do push, we assert the esp should always be above this limit. With this assertion, we ensure there is no overflow of the stack page.  


---- RATIONALE ----

>> A3: Why does Pintos implement strtok_r() but not strtok()?
Answer:
A sequence of calls to either strtok_r() or strtok() will split string into tokens which are separated by specified delimiters. The difference is that strtok() are using an internal static variable to save the processing position of the string in the previous call, while strtok_r() are using “char **save_ptr” (an external variable) passed in as a parameter.  If Pintos are using strtok(), the data races can not be avoided, because many processes may call this function multiple times and the internal static variable of strtok() cannot handle this situation. The strtok_r(), on the other hand, when called by different processes, are using different external variable “char **save_ptr” to save the processing position of the string. This avoids the potential data race.

>> A4: In Pintos, the kernel separates commands into a executable name
>> and arguments.  In Unix-like systems, the shell does this
>> separation.  Identify at least two advantages of the Unix approach.
Answer:
1. In Unix approach, a shell does the separation in the user mode. On the contrary, Pintos does this in the kernel mode. It’s clearer and safer to do the separation in the user mode level. If the separating fails for some reason, it can just fail the user shell in the user mode directly. If the user is malicious, it has less chance to affect the kernel than letting kernel doing the separation.


2. In Unix approach, the separation is done in user mode, where it could get more knowledge about its running environment, such is pwd, $HOME, $PATH and so on, so it is more powerful to handle the executable file and arguments that have relationship/dependency with its running environment.


                             SYSTEM CALLS
                             ============

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

Answer:


-- changes in syscall.h--
  ->add a variable
  struct lock filesys_lock;          /*global lock for the file system*/


  ->add a structure
  /*store opened files info*/
  struct file_info_block {
        struct file *f;                /*file structure for the opened file*/
        char *file_name;               /*file_name for the opened file*/
        int fd;                        /*file descriptor for the opened file*/
        struct list_elem elem;         /*list elem for thread's opened_file_list*/
  };


-- changes in syscall.c--
  ->add a structure
  struct global_file_block {
        block_sector_t inode_block_num; /*identification for file*/
        int ref_num;                   /*the number of threads holding this file*/
        bool is_deleted;               /*indicates the file is to be removed*/
        struct list_elem elem;         /*list elem for global_file_list*/
  };


  ->add a variable
  struct list global_file_list;             /*List of all opened files*/


--changes in process.h --
  ->add a structure
  struct wait_info_block {
        tid_t tid;               /*thread's tid*/
        struct thread *t;        /*pointer to thread*/
        int exit_code;           /*code for exit status*/
        struct list_elem elem;   /*list elem for children list of its parent*/
        struct lock l;           /*lock for this struct itself*/
        struct condition c;      /*cond for wait from the parent*/
  };


--changes in thread.h --
  ->add properties in a structure
  struct thread {
   …………………..
   /*…above untouched…*/


   #ifdef USERPROG
   /* Owned by userprog/process.c. */
    uint32_t *pagedir;                  /* Page directory. */


    int exit_code;              /*the status code when exit*/
    bool is_user;      /*indicator for user thread*/
    struct wait_info_block *wait_info; /*wait_info_block for this thread*/
    struct list child_wait_block_list;  /*list of wait_info_block of its children*/
    struct list opened_file_list;       /*list of files this thread opened*/
    int next_fd_num;                    /*next fd number for this thread locally*/
    struct file* exec_file_ptr;  /*the file which is the excutable file for this thread*/
   #endif


  /*…below untouched…*/
  ……………..
  };



>> B2: Describe how file descriptors are associated with open files.
>> Are file descriptors unique within the entire OS or just within a
>> single process?


Answer:
The file descriptors are unique just within a single process/thread. Each thread has a opened_file_list, and when the thread opens a file, it creates a file_info_block, which wraps a fd auto-incrementally generated by the thread, and pushes back the file_info_block into its opened_file_list.


When different threads open the same file, it may generates different fds (depending on the value of next_fd_num of each thread). So the same file may associate with different fds in different threads.
 

---- ALGORITHMS ----

>> B3: Describe your code for reading and writing user data from the
>> kernel.
Answer:
In system call handlers, kernel read the pointers from the user stack which points to the user data. Before dereferencing the pointers and doing read/write, it firstly verifies the pointer pointing to valid address in the following steps:


1) calculate the end_pointer by pointer + size_of_var_being_pointed - 1.
2) verify pointer and end_pointer are within user address space (below PHYS_BASE). If fails, it call a user_exit(-1), which will set the thread exit_code to -1 and call thread_exit().
3) get the page number range from pointer to end_pointer
4) try to read one byte of the address stored in pointer, pointer+PGSIZE, pointer+2*PGSIZE, …, until end_pointer, since all the continuous pages between pointer and end_pointer should be mapped and should be able to read a byte back. If the read fails, it call a user_exit(-1), which will set the thread exit_code to -1 and call thread_exit().


This is the logic for pointer verification. If the data the kernel is trying to read/write are string or buffer, we do extra verification for them.


To verify a buffer, we follow the same logic of verifying pointer, the only difference is that now the “size” used to calculate end_pointer is the size of the buffer instead of size_of_var_being_pointed.


To verify a string, we check that each of the bytes starting from (char *)str should be within user address space and should get mapped (by reading the byte back) until the end of the str, which is “\0”. If the check fails, it call a user_exit(-1), which will set the thread exit_code to -1 and call thread_exit().


After the verification above, kernel can dereferencing the user data and do read/write.


>> B4: Suppose a system call causes a full page (4,096 bytes) of data
>> to be copied from user space into the kernel.  What is the least
>> and the greatest possible number of inspections of the page table
>> (e.g. calls to pagedir_get_page()) that might result?  What about
>> for a system call that only copies 2 bytes of data?  Is there room
>> for improvement in these numbers, and how much?


Answer:
For full page data, the least number of inspection is 1 for the scenario when the 4096 bytes of data reside within one page. The greatest number is 2 for the scenario when the data span over two pages. (of course, we can check each of the bytes so it is going to be 4096 times of inspection, but this is not quite interesting). Also, one inspection scenario is just theoretical. In reality we should check twice (for the start pointer and end pointer) as a safer practice.


For two bytes of data, the least is 1 and greatest is 2 (where two bytes span two pages). 


As with optimization, for full page data, if we consider inspecting twice as an optimization compared to inspecting 4096 times, then it is. Another general optimization is not doing inspect in user space and handling page fault in exception. When the bytes reside in one or two pages which are mapped, then there is no page fault and everything goes well. If there is page fault, then we handle it in exception to take necessary action (e.g. kill the user program). 

>> B5: Briefly describe your implementation of the "wait" system call
>> and how it interacts with process termination.


Answer:
In wait system call, it first verifies the pointers in user space, then call process_wait() for the given child_tid it’s going to waiting for. 


We add a struct “wait_info_block” and a list “child_wait_block_list” in struct thread to help the wait logic. 


struct wait_info_block {
        tid_t tid;               /*thread's tid*/
        struct thread *t;        /*pointer to thread*/
        int exit_code;           /*code for exit status*/
        struct list_elem elem;   /*list elem for children list of its parent*/
        struct lock l;           /*lock for this struct itself*/
        struct condition c;      /*cond for wait from the parent*/
};


When a parent thread create a child thread, the child thread has an initialized wait_info_block, and the parent thread pushes the child’s wait_info_block into its child_wait_block_list.


When the parent thread issue a system call to “wait” for a child_tid, it first goes through its child_wait_block_list to find the corresponding wait_info_block for this child_tid. If failing to find, it’s because either the child_tid is not its child at all or “wait” has already been successfully called with the given child_tid (since if called successfully, it removes the corresponding wait_info_block from its child_wait_block_list). In either of these two cases, we just return -1 to indicate process_wait() fails. Otherwise, we check the exit_code within the found wait_info_block, if the exit_code has already become -1, which means the child thread has already been terminated by kernel, we just return -1. Otherwise, it calls cond_wait to wait for a condition: wib->t == NULL (the child process terminates). On the child process side, before it terminates, it will set the exit_code in its wait_info_block and set the condition: wib->t = NULL, and issue a cond_signal(). Then the waiting parent process will be unblocked by this signal and be able to read the exit_code from the wait_info_block to get the child exit_code. It then removes the wait_info_block from its child_wait_block_list to indicate “wait” has already been successfully called for the given child_tid and frees the memory. Finally it returns the child exit_code.


We use while-loop to wrap the cond_wait():


while(wib->t != NULL) {
    cond_wait(&wib->c, &wib->l);
}


So even if the child issues the signal and terminates before the parent waiting for it, it does not matter to miss the signal since in this case wib->t has already been updated to NULL and it will just skip the while-loop and get the exit_code from the “wib” directly.


When a process/thread terminates, it updates its wait_info_block, cleans up its child_wait_block_list, and frees all corresponding memory.


>> B6: Any access to user program memory at a user-specified address
>> can fail due to a bad pointer value.  Such accesses must cause the
>> process to be terminated.  System calls are fraught with such
>> accesses, e.g. a "write" system call requires reading the system
>> call number from the user stack, then each of the call's three
>> arguments, then an arbitrary amount of user memory, and any of
>> these can fail at any point.  This poses a design and
>> error-handling problem: how do you best avoid obscuring the primary
>> function of code in a morass of error-handling?  Furthermore, when
>> an error is detected, how do you ensure that all temporarily
>> allocated resources (locks, buffers, etc.) are freed?  In a few
>> paragraphs, describe the strategy or strategies you adopted for
>> managing these issues.  Give an example.


Answer:
For error handling, we use function and modularity to do pointer/buffer/string verification since the same or similar code can be shared by the system calls. So a system call handler just needs to call those verification functions to detect bad pointers without a morass of error-handling code in itself. 


For pointer and buffer checking, we have one function is_user_address() which takes the pointer or buffer as the first argument and the size of the variable it points to for pointers or the size of the buffer for buffers as the second argument. In is_user_address(), we calculates the end_pointer that points to the last byte of the variable or the the last byte in the buffer. Then we check the pointer/buffer and end_pointer are all within user address space. Then we check to read one byte of the address stored in pointer, pointer+PGSIZE, pointer+2*PGSIZE, …, until end_pointer, since all the continuous pages between pointer and end_pointer should be mapped and should be able to read a byte back. If any of these checks fails, is_user_address return false to indicate pointer/buffer verification fails.


For string checking, we check that each of the bytes starting from (char *)str should be within user address space and should get mapped (by reading the byte back) until the end of the str, which is “\0”. If the check fails, is_string_address_valid() return false to indicate string verification fails.


With this two helper function, we always verify pointer/buffer/string before doing further job in system call handler. In syscall_handler(), we first verify the pointer: esp. Only when it’s valid, do we continue to get the sys_call_num and dispatch it to corresponding system call handler. Then in each system call handler, we will verify its input argument(s) pointers (i.e. esp+1, esp+2, ...) using is_user_address. Then if a argument is a buffer or string we will do extra verification for the argument itself.


When a verification fails, we call a function user_exit() with -1 as argument, which finally calls process_exit(). We will check and free all the memory that needs to free in process_exit(). It sets allow write to the thread’s executable file and closes this file. It closes all its opened files and frees the memory of the corresponding wrapper structs. It frees the memory of the elemental structs in child_wait_block_list. It destroys its pagedir. It releases the file system lock if currently holding it. We also call user_exit(-1) in page_fault() if the thread causing the page fault is a user thread/process. So no matter how a thread/process terminates, it will always go through the process_exit() which will ensure all the locks, files, dynamically allocated memory, and so on to be released, closed, or freed.


For example, in sys_write_handler(), we firstly check the three pointers of the input arguments by:
is_user_address(esp+1, sizeof(int))
is_user_address(esp+2, sizeof(void **))
is_user_address(esp+3, sizeof(int))


Then, we verify the second argument since it’s a buffer by:
is_user_address((void *)buffer, *size_ptr)
,where   int *size_ptr=(int *)(esp+3);


If any of the above four verification returns false, we will call user_exit(-1); to terminate this process/thread without moving forward. Otherwise, it will continue to finish the “write” job.





---- SYNCHRONIZATION ----

>> B7: The "exec" system call returns -1 if loading the new executable
>> fails, so it cannot return before the new executable has completed
>> loading.  How does your code ensure this?  How is the load
>> success/failure status passed back to the thread that calls "exec"?


Answer:
We use a struct load_info_block to help the communication between parent and child processes. 


struct load_info_block{
        char * full_line;   /*full command line string*/
        struct semaphore sema_loaded; /*semaphore used to load thread*/
        bool success; /*whether the thread is loaded successfully*/


};


When the parent thread executing process_execute(file_name), it first creates a load_info_block, initializing its full_line as the file_name which contains the executable file name and its arguments, initializing the sema_loaded’s value to 0, and initializing success to false. Then pass this load_info_block to thread_create, and it will be the argument for start_process(). After the parent thread calls thread_create(), it blocks itself by sema_down() on the sema_loaded. 


On the child thread side, start_process() calls load() to load the executable file. Then the success flag in load_info_block will be updated by the return value of load() to indicating the success/failure of loading the child execuable. Then it issues a sema_up on the sema_loaded. 


This sema_up will unblock the parent thread. Now parent thread is able to check the success flag in the load_info_block. Then it can free the full_line inside load_info_block and also free the load_info_block itself and returns child_tid or -1 if loading fails. 


On the child thread side, after it sema_up, it checks the load() return value. If load() fails, it will set its exit_code (add in struct thread from this project) to -1 and then call thread_exit(). Thread_exit() will in turn call process_exit(), which will do all the clean up work for the failed thread. On the other hand, it load() succeeds, it will start the user process.


>> B8: Consider parent process P with child process C.  How do you
>> ensure proper synchronization and avoid race conditions when P
>> calls wait(C) before C exits?  After C exits?  How do you ensure
>> that all resources are freed in each case?  How about when P
>> terminates without waiting, before C exits?  After C exits?  Are
>> there any special cases?

Answer:
As already mentioned in part B5. When P calls wait(C) before C exits, because the “thead *” value of wait_info_block in thread C is not NULL, process P will enter the while loop:


while(wib->t != NULL) {
    cond_wait(&wib->c, &wib->l);
}


and execute cond_wait(). So the rest of the process P will have to wait until process C finished with setting wib->t to NULL and call cond_signal(). Since for each wait_info_block, there is one child process with one parent process, we achieved synchronization and avoid race conditions.


When P calls wait(C) after C exits, the wib->t of process C has already been updated to NULL and the process P will just skip the while-loop and get the exit_code from the “wib” directly. Because C already exited, there will be no synchronization and race condition, and this approach successfully handled this situation.


For the two cases mentioned above, process P may call wait(C) either before or after process C exits, we only clean up the wait_info_block memory allocation after P exits. We have a list “child_wait_block_list” in the parent process to keep track of all the “waited_info_block”s of its children processes(whether they are terminated or not). When P exits, it will go through the “child_wait_block_list” to free the memory used for its children processes’ waited_info_block. So both cases are guaranteed to have their memory allocation cleaned up.
When P terminates without waiting, before C exits, it will updates its own wait_info_block:
/*update wait_info_block if its parent process still exists*/
  if(wib != NULL){
          lock_acquire(&wib->l);
          wib->exit_code = cur->exit_code;
          wib->t = NULL;
          cond_signal(&wib->c, &wib->l);
          lock_release(&wib->l);
          }


and go through the “child_wait_block_list” to free the memory used for its children processes’ wait_info_block using below:


  struct list *child_list = &cur->child_wait_block_list;
  while(!list_empty(child_list)) {
          wib = list_entry (list_pop_front(child_list), struct wait_info_block, elem);


          lock_acquire(&wib->l);
          list_remove(&wib->elem);
          if (wib->t != NULL) {
                  wib->t->wait_info = NULL;
          }
          lock_release(&wib->l);
          free(wib);
   }


where “wib->t->wait_info = NULL;” will set C->wait_info into NULL. So when C exit later, it will not free its own wait_info again.


When P terminates without waiting, after C exits, using the same snippet above, process P will clear up C’s wait_info without any trouble. 


One special case is that P and C exit at the same time, there maybe some synchronization and race conditions issues. But we already add lock in each wait_info_block, every operation on the wait_info_block will need to acquire that lock first. So the potential synchronization and race conditions are avoided. 





---- RATIONALE ----

>> B9: Why did you choose to implement access to user memory from the
>> kernel in the way that you did?
Answer:
we divided the pointer verification into two different categories and using different functions to handle each case:


/*check if the pointer (with size length) point  to a valid space*/
static bool is_user_address(const void *pointer, int size)


/*check if the a string's address is valid*/
static bool is_string_address_valid(const void *pointer)


For each byte pointer, to make sure it is valid, we need 3 step verification to make sure (1)the pointer is not null (2) the virtual address is mapped (3) pointer is not pointed to kernel virtual address space, so it will consume a lot of time if we want to check a whole block of pointers. When we know the start pointer and the size of the memory that we want to check, instead of check byte pointer one by one, we can check only one byte pointer per page it may spanned over. That is exactly what function “is_user_address(const void *pointer, int size)” does, which is much faster than the byte-wise checking. However, in some cases, like string address checking, we do not know the size in advance, we still need byte-wise checking until it hits the end by “is_string_address_valid(const void *pointer)”.


In syscall_handler(), we first using “is_user_address” to validate pointer esp because every system call need the value of sys_call_num. Then, for each system call, we using above two different verification functions according to the verification categories. In this way, we can save unnecessary byte pointers’ 3 step verification. 


>> B10: What advantages or disadvantages can you see to your design
>> for file descriptors?
Answer:
Our implementation is using a linked list called “opened_file_list” to keep track of the name and file descriptor of all the opened files for a process, and a global linked list “global_file_list” to record the opened files information of all processes in the entire system.


Advantages: 
(1)Both  “opened_file_list” and “global_file_list” are with dynamic allocated, namely, the space they took will change according to the runtime situation, no extra space is wasted.  (2)When open a file, maintain the “opened_file_list” for current thread will only take O(1). Because we only need to create a new file_info_block and push it into the linked list. 
(2)we put the file_info_block struct here for reference
struct file_info_block {
        struct file *f;                /*file structure for the opened file*/
        char *file_name;               /*file_name for the opened file*/
        int fd;                        /*file descriptor for the opened file*/
        struct list_elem elem;         /*list elem for thread's opened_file_list*/
  };
This is the element struct for “opened_file_list” to keep the info of opened files in each process. The file_name part is dynamically allocated to hold the file name with exact length, so no extra memory is wasted.




Disadvantages: 
(1)every time we perform open/close a file, we may need to maintain the “global_file_list”, which need to check if the file we are about to open exists in the “global_file_list”. The complexity is O(N).
(2)every time we perform write, read, and all other operations on file based on the file descriptor, we need to traverse the “opened_file_list”, which has a O(N) complexity.
Both can be avoided if we are using a hash table or a in-order array.



>> B11: The default tid_t to pid_t mapping is the identity mapping.
>> If you changed it, what advantages are there to your approach?


Answer:
We didn’t change the default identical tid_t to pid_t mapping, we used those interchangeably because in this project (Pintos) one process only has one thread. Under such circumstances, changing it to other mapping will make no difference.


But if we are dealing with a system that needs to deal with process with multiple threads, we have to change this identical mapping.


                           SURVEY QUESTIONS
                           ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?


Answer: 
It took more time than project1. The argument passing is easier compared with system call part. 
Some of the system call implementation is tricky especially when it is related to process_wait, process_exit, start_process, load, and page_fault. We spent relatively long time on the test case multi-oom, since we have slight memory leak in our original design which is related to opening/closing files. In a nutshell, this assignment is more challenging but still very interesting.


>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

Answer:
The argument passing part gives us more detailed understanding about the mechanism of function-calling and stack frame structure.

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

Answer:
All the materials about the project are in great detail.

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

Answer: No.

>> Any other comments?


Answer: No.